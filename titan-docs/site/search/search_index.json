{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\udef0\ufe0f Titan Orchestrator","text":"<p>Titan is a lightweight distributed execution runtime designed to bridge the gap between Logical DAG Orchestrators (e.g., Airflow/Dagster), Dynamic Agent Runtimes (LLM-driven systems), and Service Schedulers (Micro-PaaS for long-running APIs).</p> <p>Traditional workflow engines are responsible for deciding task order. Titan is responsible for deciding:</p> <ul> <li>Where it runs: Enforcing data locality and node affinity.</li> <li>How it dynamically scales: Real-time load detection for auto-scaling up and graceful descale.</li> <li>How execution survives failure: Zero-loss state recovery via the TitanStore AOF.</li> <li>Which hardware executes which task: Capability-based GPU vs. CPU routing.</li> </ul> <p>All within a single zero-dependency binary.</p> <pre><code>flowchart LR\n    subgraph Clients[\"User / Clients\"]\n        direction TB\n        SDK[\"Python SDK Agent\"]\n        YAML[\"YAML Pipeline\"]\n        Dash[\"Web Dashboard\"]\n    end\n\n    subgraph ControlPlane[\"Titan Control Plane\"]\n        Master[\"Titan Master\"]\n    end\n\n    subgraph DataLayer[\"State &amp; Persistence\"]\n        Store[(\"Titan Store&lt;br&gt;(Optional)\")]\n    end\n\n    subgraph Grid[\"Compute Grid\"]\n        direction TB\n        W1[\"Worker Node\"]\n        W2[\"Worker Node\"]\n        W3[\"Worker Node\"]\n    end\n\n    SDK -- \"Submit Job\" --&gt; Master\n    YAML -- \"Submit Job\" --&gt; Master\n\n    Master -- \"Distribute\" --&gt; W1\n    Master -- \"Distribute\" --&gt; W2\n    Master -- \"Distribute\" --&gt; W3\n\n    W1 -. \"Data Bus (IPC)\" .-&gt; Master\n    W2 -. \"Data Bus (IPC)\" .-&gt; Master\n    W3 -. \"Data Bus (IPC)\" .-&gt; Master\n\n    Master -. \"Stream Stats\" .-&gt; Dash\n    W1 -. \"Live Logs\" .-&gt; Master\n\n    Master &lt;--&gt;|\"AOF / State / Data Bus\"| Store\n\n    classDef optional fill:#f9f9f9,stroke:#333,stroke-dasharray: 5 5;\n    class Store optional;</code></pre>"},{"location":"#the-capability-spectrum","title":"\ud83d\udcc8 The Capability Spectrum","text":"<p>Titan is designed to grow with your system's complexity:</p> <ol> <li>Level 1: Distributed Cron (The \"Scheduler\")    Run Python scripts on a remote machine in a specified sequence or distributed in parallel. </li> <li>Level 2: Service Orchestrator (The \"Platform\")    Deploy long-running API servers and keep them alive, restarting them automatically on crash.</li> <li>Level 3: Agentic Execution Runtime (The \"Autonomous Mode\")    Programmatically construct execution graphs at runtime where software agents spawn downstream compute tasks conditionally based on LLM decisions or system states.</li> </ol>"},{"location":"#built-in-dashboard","title":"\ud83d\udcca Built-In Dashboard","text":"<p>Titan includes a lightweight Python Flask dashboard to visualize cluster health, monitor worker load, and stream stdout/stderr from distributed jobs in real-time.</p> <p></p>"},{"location":"#live-log-streaming","title":"Live Log streaming","text":"<p>Monitor remote worker execution directly from the control plane UI in real-time.</p> <p></p>"},{"location":"#included-examples","title":"\ud83e\udde9 Included Examples","text":"<p>The repository includes a comprehensive <code>titan_test_suite/</code> with ready-to-run examples demonstrating Titan's full range of capabilities: The examples are added as folders for each category,</p> <ul> <li>Static YAML Pipelines: Templates for basic Diamond Patterns, massive parallel Fan-outs, and strict hardware-aware routing (e.g., forcing tasks to <code>GPU</code> nodes).</li> <li>Dynamic Logic Switches: Python SDK scripts that simulate measuring system traffic and dynamically spawn entirely different DAGs on the fly.</li> <li>Autonomous Agents: A recursive, self-healing agent that tracks its own retry attempts globally via TitanStore and spawns clones across the cluster until a fragile task succeeds.</li> <li>Dagster Integration: A complete hybrid pipeline where Dagster manages the UI and data lineage, while Titan handles the physical distributed compute and log streaming.</li> </ul> <p>\ud83d\udca1 Built with Titan: The official JavaDocs for the Titan Core Engine were completely generated, zipped, and distributed using Titan itself as the execution runtime!</p> <p>\ud83d\ude80 Quickstart: Run your first distributed task in 5 minutes \ud83e\udde0 Read the Architecture Deep Dive</p>"},{"location":"contributing/","title":"\ud83e\udd1d Contributing &amp; Testing","text":"<p>Found a bug? Please log an issue on GitHub! Since this is a custom-built distributed system, edge cases are expected.</p>"},{"location":"contributing/#testing-strategy","title":"Testing Strategy","text":"<p>\u26a0\ufe0f Note to Contributors: Titan is a research prototype built to explore the \"Hard Parts\" of Distributed Systems. As such, the test coverage focuses on integration rather than unit purity.</p> <ul> <li>Java Tests (<code>src/test/java</code>): These are essentially Integration Tests designed during the initial Proof-of-Concept phase to validate the core loop. Some of these may be outdated or flaky due to the rapid pace of architectural changes.</li> <li>Python Validation: The primary method for validating system stability currently lies in the <code>titan_test_suite</code> folder. Scripts like <code>complex_dag_test.py</code> and the YAML examples perform end-to-end black-box testing of the cluster.</li> <li>Future Plan: A comprehensive Engine Test Suite and proper Unit Tests are planned for the near future to improve stability.</li> </ul>"},{"location":"contributing/#license-attribution","title":"License &amp; Attribution","text":"<p>Titan Orchestrator is licensed under the Apache License 2.0. See the <code>LICENSE</code> file in the root repository for full details.</p> <p>Created and Maintained by Ram Narayanan A S \u00a9 2026 Titan Orchestrator. Open for contributions.</p> <p>Engineered from first principles to deconstruct the fundamental primitives of distributed orchestration.</p>"},{"location":"getting-started/","title":"\ud83d\ude80 Getting Started","text":"<p>Get a Titan Master, Worker node, and the UI Dashboard running locally in under 5 minutes.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed on your machine:</p> <ul> <li>Java 17+ (For the Core Engine)</li> <li>Python 3.10+ (For the SDK, CLI, and Dashboard)</li> <li>Maven (To build the Java project)</li> </ul>"},{"location":"getting-started/#building-the-engine","title":"Building the Engine","text":""},{"location":"getting-started/#1-clone-the-engine","title":"1. Clone the Engine","text":"<p>Titan compiles down into a single, ultra-lightweight \"Uber-JAR\". We will build it and place it in the <code>perm_files</code> directory, which acts as Titan's artifact registry.</p> <pre><code>git clone https://github.com/ramn51/titan-orchestrator.git\ncd titan-orchestrator\n</code></pre>"},{"location":"getting-started/#option-11-run-via-intellij-recommended-for-dev","title":"Option 1.1: Run via IntelliJ (Recommended for Dev)","text":"<p>If you are developing Titan, simply open the project in IntelliJ IDEA and run the Main classes directly:</p> <ol> <li>Master: Run <code>titan.TitanScheduler</code></li> <li>Worker: Run <code>titan.TitanWorker</code> (Defaults to Port 8080, Capability: GENERAL, Permanent: False)</li> <li>CLI: Run <code>titan.TitanCli</code></li> </ol>"},{"location":"getting-started/#option-12-build-the-core-engine","title":"Option 1.2. Build the core engine","text":"<pre><code>mvn clean package\n</code></pre>"},{"location":"getting-started/#2-stage-the-binary-for-execution-optional-there-will-be-a-workerjar-already-there","title":"2. Stage the binary for execution (Optional, there will be a Worker.jar already there)","text":"<pre><code>cp target/titan-orchestrator-1.0-SNAPSHOT.jar perm_files/Worker.jar\n</code></pre>"},{"location":"getting-started/#3-configure-the-runtime-titanproperties","title":"3. Configure the Runtime (titan.properties)","text":"<p>Titan uses an Adapter Pattern for its state management, meaning the persistence layer is entirely pluggable. To connect the Master to your Redis (TitanStore) instance for state recovery and data-bus features, create a titan.properties file in the root directory where you run the JAR.</p> <p>Create <code>titan.properties</code>:</p> <p>Properties <pre><code># TitanStore (Redis) Connection\ntitan.redis.host=localhost\ntitan.redis.port=6379\n\n# Cluster Tuning\ntitan.worker.heartbeat.interval=10\ntitan.worker.pool.size=10\n</code></pre></p> <p>Note: If this file is missing, Titan will gracefully degrade to sensible defaults (purely in-memory execution with no persistence or recovery) or attempt to connect to Redis on localhost:6379.</p>"},{"location":"getting-started/#start-the-cluster","title":"Start the Cluster","text":""},{"location":"getting-started/#5-start-titanmaster-and-titanworker","title":"5. Start TitanMaster and TitanWorker","text":"<p>Terminal 1 (The Master Scheduler): This starts the control plane on default port <code>9090</code>. It will listen for worker heartbeats and incoming DAG submissions.</p> <pre><code>java -cp target/titan-orchestrator-1.0-SNAPSHOT.jar titan.TitanMaster\n</code></pre> <p>Terminal 2 (The Default Worker Node): This starts a general-purpose hardware node. By default, it connects to the local Master on port <code>9090</code> and opens itself for task execution on port <code>8080</code>.</p> <pre><code>java -cp target/titan-orchestrator-1.0-SNAPSHOT.jar titan.TitanWorker\n</code></pre> <p>(You should immediately see a \"Worker Registered\" log appear in Terminal 1).</p> <p>\u26a1 Advanced Worker Configurations You can easily spawn specialized nodes by passing arguments: <code>[Port] [MasterIP] [MasterPort] [Capability] [isPermanent]</code></p> <p>Example: Spawn a persistent GPU worker on port 8081: <pre><code>java -cp target/titan-orchestrator-1.0-SNAPSHOT.jar titan.TitanWorker 8081 localhost 9090 GPU true\n</code></pre></p>"},{"location":"getting-started/#5-install-the-python-sdk","title":"5. Install the Python SDK","text":"<p>The Titan Python SDK allows you to submit jobs, define DAGs, and interact with the cluster programmatically.</p> <p>Open a third terminal window and install the SDK in editable mode:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"getting-started/#6-run-your-first-task","title":"6. Run Your First Task","text":"<p>Let's deploy a pre-configured YAML DAG to the cluster using the Titan CLI.</p> <pre><code>python titan_sdk/titan_cli.py deploy titan_test_suite/examples/yaml_based_static_tests/dag_structure_test\n</code></pre> <p>What just happened?</p> <ol> <li>The CLI parsed the YAML definition and zipped the required Python scripts.</li> <li>It dispatched the payload to the Master node via Titan's custom binary protocol.</li> <li>The Master resolved the dependency graph and routed the tasks to your idle Worker node.</li> <li>The Worker executed the code in an isolated workspace!</li> </ol>"},{"location":"getting-started/#7-open-the-dashboard-optional","title":"7. Open the Dashboard (Optional)","text":"<p>Titan includes a lightweight Flask dashboard to visualize cluster health and stream live logs. To spin it up, run:</p> <pre><code>python3 ./perm_files/server_dashboard.py\n</code></pre> <p>Navigate to <code>http://localhost:5000</code> in your browser to see your Worker node's live CPU/Thread load and the history of the DAG you just ran.</p>"},{"location":"architecture/design/","title":"\ud83c\udfdb\ufe0f Architecture &amp; System Design","text":"<p>Titan follows a Leader-Follower topology with a decoupled control plane. It is engineered from first principles to deconstruct the fundamental primitives of distributed orchestration without relying on heavy external frameworks.</p> <p>This is the L1 Diagram with highest level of abstraction.</p> <p>There will be a single Master, Master is the single point of contact for the user, worker and the titan store.</p> <ul> <li> <p>Users can submit jobs either as a YAML or a Python script through TitanSDK.</p> </li> <li> <p>Scheduler routes to the Worker node (either based on load or capability as per definition). </p> </li> <li> <p>Workers are spawned independently and gets registered to the Scheduler. Scheduler will not have predefined information about the workers. (gets updated only on registration).</p> </li> <li> <p>Scheduler uses TitanStore to trace the state of the system and for recovery replay. Tasks will communicate through Scheduler to use the Titan Store. </p> </li> <li> <p>Titan Store is accessed only by Scheduler instance and is single point of communication.</p> </li> </ul> <p>Scheduler for now is SPOF (Single point of failure).</p> <pre><code>flowchart LR\n    subgraph Clients[\"User / Clients\"]\n        direction TB\n        SDK[\"Python SDK Agent\"]\n        YAML[\"YAML Pipeline\"]\n        Dash[\"Web Dashboard\"]\n    end\n\n    subgraph ControlPlane[\"Titan Control Plane\"]\n        Master[\"Titan Master\"]\n    end\n\n    subgraph DataLayer[\"State &amp; Persistence\"]\n        Store[(\"Titan Store&lt;br&gt;(Optional)\")]\n    end\n\n    subgraph Grid[\"Compute Grid\"]\n        direction TB\n        W1[\"Worker Node\"]\n        W2[\"Worker Node\"]\n        W3[\"Worker Node\"]\n    end\n\n    SDK -- \"Submit Job\" --&gt; Master\n    YAML -- \"Submit Job\" --&gt; Master\n\n    Master -- \"Distribute\" --&gt; W1\n    Master -- \"Distribute\" --&gt; W2\n    Master -- \"Distribute\" --&gt; W3\n\n    W1 -. \"Data Bus (IPC)\" .-&gt; Master\n    W2 -. \"Data Bus (IPC)\" .-&gt; Master\n    W3 -. \"Data Bus (IPC)\" .-&gt; Master\n\n    Master -. \"Stream Stats\" .-&gt; Dash\n    W1 -. \"Live Logs\" .-&gt; Master\n\n    Master &lt;--&gt;|\"AOF / State / Data Bus\"| Store\n\n    classDef optional fill:#f9f9f9,stroke:#333,stroke-dasharray: 5 5;\n    class Store optional;</code></pre>"},{"location":"architecture/design/#deep-dive-l2-diagram","title":"Deep Dive L2 Diagram","text":"<p>Network Topology: Titan currently assumes a flat network address space (LAN/VPC). While it can run on Cloud VMs (EC2/GCP), it requires direct TCP connectivity between nodes. </p>"},{"location":"architecture/design/#1-the-protocol-titan_proto","title":"1. The Protocol (<code>TITAN_PROTO</code>)","text":"<p>Titan does not rely on HTTP/REST or heavy gRPC layers. Communication happens over raw TCP sockets using a fixed-header framing strategy to ensure integrity and prevent packet fragmentation. </p> <pre><code>[ HEADER (8 Bytes) ]\n| Version (1B) | OpCode (1B) | Flags (1B) | Spare (1B) | Payload Length (4B) |\n\n[ BODY ]\n| Binary Payload (Variable) ... |\n</code></pre> <p>This ensures lightning-fast IPC (Inter-Process Communication) with very less latency and zero JSON-serialization overhead for the core execution loops.</p>"},{"location":"architecture/design/#2-internal-mechanics","title":"2. Internal Mechanics:","text":"<p>The Master NodeThe Master acts as the Scheduler and Control Plane. It utilizes specialized threads to manage the cluster efficiently.</p> <ul> <li> <p>Inverted Worker Registration (Push-Based Discovery)</p> <p>Unlike traditional systems that scan for nodes, Titan uses a Push-Based Discovery model. Workers initiate the connection to the Master, allowing dynamic scaling behind NATs or firewalls without static IP configuration.</p> </li> <li> <p>Queue Segregation (Waiting vs. Active)</p> <p>To process complex DAGs efficiently, Titan separates tasks by readiness. Jobs with unresolved parent dependencies are never placed in the active loop; instead, they sit in a blocked Waiting Queue. Once a parent task succeeds, a state-transition event instantly unlocks the dependent children, moving them into the ActiveJobQueue for immediate execution.</p> </li> <li> <p>Smart Dispatching: Capability &amp; Affinity Routing</p> <p>When popping a job from the ActiveJobQueue, the Master executes a two-phase routing algorithm before dispatching the payload:</p> <p>Capability-Based Routing: The scheduler checks the job's requirement tag (e.g., GPU, HIGH_MEM) and strictly matches it against the registered hardware tags of the current worker pool. A GPU task will bypass idle GENERAL nodes until a capable node is free.</p> <p>Affinity-Based Routing: If a task requires strict data locality (flagged with affinity: true), the Master queries TitanStore to find the exact physical node that executed the parent task. The child task is then routed exclusively to that node to leverage local filesystem caches and avoid network data transfers.</p> </li> <li> <p>The \"ClockWatcher\"</p> <p>Instead of inefficient polling, Titan uses a dedicated thread monitoring a DelayQueue to handle future tasks. This ensures $O(\\log n)$ scheduling efficiency, consuming zero CPU cycles until the precise millisecond a job is ready.</p> </li> <li> <p>Reconciliation Loop</p> <p>A background ScalerExecutor runs every 15 seconds to compare the ActiveJobQueue against WorkerCapacity. If the delta is too high, it triggers the Auto-Scaler. It calculates saturation per capability pool (e.g., GENERAL vs. GPU) to ensure scaling only happens when a specific resource type is exhausted.</p> </li> <li> <p>The Failure Detector (Heartbeats)</p> <p>The Master maintains a dedicated HeartBeatExecutor. It tracks the \"Last Seen\" timestamp of every worker. If a worker goes silent for &gt;30s, it is marked DEAD, and its active jobs are immediately re-queued to healthy nodes to guarantee execution resilience.</p> </li> <li> <p>Dead Letter Queue (DLQ) &amp; Poison Pills</p> <p>If a task repeatedly crashes a worker or fails beyond its maximum retry threshold (e.g., due to a syntax error or a missing system library), it is safely removed from the execution loop to prevent infinite crash-looping. The Master quarantines these \"poison pill\" tasks in a Dead Letter Queue (DLQ), preserving their logs and state for operator inspection without stalling the rest of the cluster.</p> </li> </ul>"},{"location":"architecture/design/#3-state-persistence-data-bus-titanstore","title":"3. State Persistence &amp; Data Bus (TitanStore)","text":"<p>To eliminate the Master as a single point of failure and provide a unified state layer, Titan implements a custom in-memory data store backed by Redis primitives (RedisJava).</p> <p>Append-Only File (AOF): </p> <p>Every critical system transition (e.g., Node Locked, Job Dispatched, Worker Registered) is written to a persistent log on disk.</p> <p>Crash Recovery: </p> <p>If the Master process is killed abruptly, it does not lose the cluster state. Upon restart, it reads the AOF, reconstructs the ActiveJobQueue, and resumes the DAG exactly where it left off.</p> <p>Distributed Data Passing: </p> <p>Tasks can write intermediate results or metadata to the store, allowing downstream tasks to fetch them seamlessly across completely different physical nodes.</p> <p>Dynamic State Tracking: </p> <p>Individual tasks can update their own custom progress metrics, flags, or statuses during execution. This allows the Python SDK or the UI Dashboard to query the real-time progress of a remote script while it is still running.</p>"},{"location":"architecture/design/#4-the-data-plane-file-system","title":"4. The Data Plane (File System)","text":"<p>Titan strictly separates \"Source Artifacts\" from \"Runtime State\" to ensure reproducibility.</p> Directory Role Description <code>TitanStore (Redis) (Optional)</code> Global State In-memory data structure store backed by an AOF. Stores job statuses, DAG locks, Task  and worker heartbeats. Can be used by tasks as a store as well. <code>perm_files/</code> Artifact Registry The \"Source of Truth.\" Place your scripts (<code>.py</code>, <code>.sh</code>) and binaries (<code>.jar</code>) here.Note: SDK/YAML submissions automatically stage files here, but you can also manually drop files in. <code>titan_workspace/</code> Execution Sandbox The runtime staging area.\u2022 <code>jobs/{id}/</code>: Contains execution logs (<code>.log</code>) and isolated script copies for specific jobs.\u2022 <code>shared/</code>: A \"Data Bus\" directory allowing dependent DAG tasks to share intermediate files."},{"location":"architecture/design/#5-orchestration-flows","title":"5. Orchestration Flows","text":"<p>Titan handles both delegated and autonomous orchestration.</p>"},{"location":"architecture/design/#flow-a-delegated-orchestration-dagster-titan","title":"Flow A: Delegated Orchestration (Dagster + Titan)","text":"<p>Dagster holds the logical execution graph and delegates physical execution to Titan via a synchronous polling loop.</p> <p></p>"},{"location":"architecture/design/#flow-b-autonomous-orchestration-native-titan","title":"Flow B: Autonomous Orchestration (Native Titan)","text":"<p>The Python SDK submits the entire DAG in one atomic binary payload. The Titan Master handles the complete state machine (Wait -&gt; Unlock -&gt; Dispatch) internally.</p> <p></p>"},{"location":"architecture/design/#6-limitations-design-constraints","title":"6. Limitations &amp; Design Constraints","text":"<p>Titan is a research runtime designed to explore the primitives of orchestration (Scheduling, IPC, State Management) without the complexity of existing frameworks. As such, certain \"Production\" features are explicitly out of scope for V1:</p>"},{"location":"architecture/design/#current-constraints","title":"Current Constraints","text":"<ol> <li> <p>Security (Open TCP):</p> <ul> <li>The current implementation uses raw, unencrypted TCP sockets.</li> <li>Constraint: Do not run Titan on public networks (WAN) without a VPN or SSH Tunnel. Use strictly within a trusted VPC/LAN.</li> <li>State Loss (Solved in v1.5): </li> </ul> </li> <li> <p>The Master node now utilizes TitanStore (RedisJava) for state persistence. If the Master process dies, the cluster state is fully recovered from the AOF upon restart.</p> </li> <li> <p>Process Failover:</p> <ul> <li>While data is safe, the Master is currently a singleton process. If it crashes, workers cannot receive new instructions until it reboots. High Availability (HA) via Raft Consensus (Leader Election) is planned for the v2.0 Roadmap to achieve true zero-downtime failover.</li> </ul> </li> <li> <p>Network Topology:</p> <ul> <li>Titan assumes a flat address space (all nodes can ping each other via IP). It does not currently handle NAT Traversal or complex Subnet routing.</li> </ul> </li> <li> <p>Scaling Boundary (Process vs. Infrastructure):</p> <ul> <li>Titan implements Application-Level Scaling (spawning new JVM worker processes on existing hardware).</li> <li>Infrastructure Provisioning is currently delegated to external tools.</li> <li>Roadmap Item: A \"Cluster Autoscaler Interface\" (Webhooks) is planned for v2.0, allowing Titan to trigger external APIs (e.g., Azure VM Scale Sets) when the cluster runs out of capacity.</li> </ul> </li> </ol>"},{"location":"architecture/design/#7-roadmap-to-v20","title":"7. Roadmap to v2.0","text":"<p>Security &amp; Auth: Implement mTLS (Mutual TLS) for encrypted, authenticated communication.</p> <p>Distributed Consensus: Implement Raft/Paxos for Leader Election (Removing Master SPOF).</p> <p>Containerization: Support for Docker execution drivers for true filesystem isolation (currently uses Process-Level isolation).</p> <p>Cluster Autoscaler Webhooks: Allow Titan to trigger external APIs (e.g., Azure VM Scale Sets) to provision bare metal automatically.</p> <p>Human-in-the-loop Webhooks: Allow Titan to trigger a HIL hooks to proceed in the DAG further, this should pause the DAG and its execution states and resume based on approval.</p>"},{"location":"architecture/internals/","title":"\u2699\ufe0f Internals: Protocol &amp; TitanStore","text":"<p>Titan achieves its zero-dependency architecture by implementing its own network communication and state management layers from scratch. This page covers how nodes talk to each other and how cluster state survives failure.</p>"},{"location":"architecture/internals/#1-the-wire-protocol-titan_proto","title":"1. The Wire Protocol (<code>TITAN_PROTO</code>)","text":"<p>Titan does not rely on HTTP/REST or heavy gRPC layers for internal orchestration. To maximize performance and minimize the memory footprint of the core engine, node-to-node communication happens over simple TCP sockets using a custom binary protocol.</p> <p>Every message sent across the cluster uses a fixed-header framing strategy. This ensures payload integrity and prevents the fragmentation issues inherent to plain TCP streams.</p> Bytes Field Description <code>0</code> Version Protocol version (currently <code>0x01</code>). <code>1</code> OpCode The instruction (e.g., <code>0x04</code> = Submit DAG, <code>0x16</code> = Fetch Logs). <code>2</code> Flags Bitmask for modifiers (e.g., Compression, Encryption). <code>3</code> Spare Reserved for future use. <code>4-7</code> Payload Length 32-bit unsigned integer defining the exact size of the incoming body. <code>8+</code> Body The variable-length binary or string payload. <p>This header adds exactly 8 bytes of overhead per message, achieving very low latency without JSON serialization overhead.</p>"},{"location":"architecture/internals/#2-titanstore-architecture-powered-by-jkredis","title":"2. TitanStore Architecture (Powered by JKRedis)","text":"<p>To eliminate the Master as a Single Point of Failure (SPOF) and provide a distributed data bus, Titan integrates TitanStore (built on JKRedis). It is a multi-threaded, persistent Redis clone built from scratch in Java using standard I/O (<code>ServerSocket</code>), requiring no external frameworks like Netty.</p>"},{"location":"architecture/internals/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>In-Memory Storage: Thread-safe key-value and set storage using <code>ConcurrentHashMap</code>.</li> <li>RESP Protocol: Full implementation of the Redis Serialization Protocol, making it fully compatible with official Redis clients (<code>redis-cli</code>, <code>Jedis</code>, etc.).</li> <li>Concurrent Networking: Handles multiple concurrent worker connections using a custom Thread Pool architecture.</li> </ul>"},{"location":"architecture/internals/#advanced-systems-features","title":"Advanced Systems Features","text":"<ul> <li>Persistence (AOF): Implements Append-Only File logging. Every DAG state transition is flushed to disk. If the Master crashes, data survives and is replayed on startup for zero-loss Crash Recovery.</li> <li>Real-Time Pub/Sub: Implements the Publish/Subscribe messaging pattern using a fan-out architecture with <code>CopyOnWriteArrayList</code> to safely manage concurrent subscribers without blocking publishers.</li> <li>Expiry &amp; Eviction (TTL): Supports millisecond-precision expiration using both Lazy Eviction (checked on access) and Active Eviction (a background probabilistic thread cleans up keys every 100ms).</li> <li>Master-Replica Replication: Supports full PSYNC handshakes and real-time command propagation for distributed high availability.</li> </ul>"},{"location":"architecture/internals/#3-supported-data-bus-commands","title":"3. Supported Data Bus Commands","text":"<p>Tasks running on the cluster can interact with TitanStore using the Python SDK. Under the hood, the store supports the following core RESP commands, including standard Key-Value operations and Set mathematics.</p> Command Usage Description <code>SET</code> <code>SET key value [PX ms]</code> Stores a string value. Optional <code>PX</code> flag sets an automatic expiration timer. <code>GET</code> <code>GET key</code> Retrieves a string value. Returns null if expired or missing. <code>SADD</code> <code>SADD key member</code> Adds a member to a Set. Returns <code>1</code> if the member was added, <code>0</code> if it already existed. <code>SMEMBERS</code> <code>SMEMBERS key</code> Returns all members currently stored in the specified Set. <code>SREM</code> <code>SREM key member</code> Removes a specific member from a Set. Returns <code>1</code> if removed, <code>0</code> if it wasn't there. <code>PUBLISH</code> <code>PUBLISH channel msg</code> Broadcasts a message to all workers subscribed to the channel. <code>SUBSCRIBE</code> <code>SUBSCRIBE channel</code> Listens for real-time messages on a specific channel."},{"location":"architecture/internals/#4-how-titan-uses-the-store","title":"4. How Titan Uses the Store","text":"<p>While you can use TitanStore to pass data between your own Python tasks, the Titan Master heavily relies on it internally:</p> <ol> <li>Worker Registry: Heartbeats and node capabilities are stored as ephemeral keys with TTLs. If a worker dies, its key naturally expires, triggering the failure detector.</li> <li>DAG Locks: Dependencies are managed using atomic <code>SET</code> commands. Child tasks constantly check the store to see if their parent's execution flag has been set to <code>COMPLETED</code>.</li> <li>Log Streaming: The web dashboard uses the Pub/Sub architecture to subscribe to specific job IDs, allowing the Master to stream physical stdout/stderr logs directly to the UI in real-time.</li> </ol>"},{"location":"examples/agentic/","title":"\ud83d\udc0d Programmatic &amp; Agentic Workflows","text":"<p>While YAML is excellent for static, predictable pipelines, modern infrastructure often requires dynamic decision-making. </p> <p>The Titan Python SDK allows you to break out of static configurations and use standard Python code to generate execution graphs programmatically. This enables everything from simple conditional logic to fully autonomous AI agents that generate their own execution paths at runtime.</p> <p>To execute the scripts if you have installed the sdk globally with <code>pip install -e .</code> then, you can simply run it as <code>python &lt;script_name&gt;.py</code></p> <p>For direct examples to run check out these:</p> <p>For Agentic:</p> <p><code>titan_test_suite/examples/agents_example/code_healer_agent.py</code> <code>titan_test_suite/examples/agents_exampels/doc_generator_agent/tools/doc_dispatcher.py</code></p> <p>For Deterministic:</p> <p><code>titan_test_suite/examples/dynamic_dag_custom/dynamic_dag_switch</code> <code>titan_test_suite/examples/worker_skill_based_test/gpu_project_test</code></p>"},{"location":"examples/agentic/#1-defining-dags-programmatically-the-basics","title":"1. Defining DAGs Programmatically (The Basics)","text":"<p>Using the SDK, you construct units of work using the <code>TitanJob</code> class and define their dependencies (<code>parents</code>). When you submit them as a list, Titan's Master node automatically resolves the DAG and distributes the workload.</p> <pre><code>from titan_sdk import TitanClient, TitanJob\n\nclient = TitanClient(host=\"localhost\", port=9090)\n\n# 1. Define the Root Task\ntask_a = TitanJob(\n    job_id=\"extract_data\",\n    filename=\"etl/extract.py\",\n    priority=5\n)\n\n# 2. Define a Dependent Task\ntask_b = TitanJob(\n    job_id=\"train_model\",\n    filename=\"ml/train.py\",\n    requirement=\"GPU\",\n    parents=[\"extract_data\"] # &lt;--- Defines the dependency\n)\n\n# 3. Submit them as a unified DAG\nclient.submit_dag(\"nightly_pipeline\", [task_a, task_b])\nprint(\"DAG Submitted Successfully!\")\n</code></pre>"},{"location":"examples/agentic/#2-dynamic-logic-mode-15","title":"2. Dynamic Logic (Mode 1.5)","text":"<p>Best for: Conditional logic, real-time load balancing, and dynamic infrastructure.</p> <p>Because you are using pure Python, you can use standard if/else logic to decide which execution graph to build based on real-time cluster stats, database queries, or external API calls.</p> <p>The \"Logic Switch\" In this scenario, our script checks the current traffic load. If traffic is high, it submits a single, lightweight task. If traffic is low, it dynamically generates a massive parallel \"Deep Analysis\" DAG.</p> <p></p> <pre><code>from titan_sdk import TitanClient, TitanJob\n\nclient = TitanClient()\ntraffic_load = get_current_traffic() # Your custom monitoring logic\n\nif traffic_load &gt; 80:\n    print(\"[HIGH] High Traffic. Switching to lightweight 'FAST' pipeline.\")\n    fast_job = TitanJob(job_id=\"fast_scan\", filename=\"fast_path.py\")\n    client.submit_job(fast_job)\nelse:\n    print(\"[LOW] Normal Traffic. Generating distributed 'DEEP' analysis DAG.\")\n    # Programmatically generate 10 parallel tasks\n    deep_tasks = [\n        TitanJob(job_id=f\"deep_{i}\", filename=\"deep_path.py\") \n        for i in range(10)\n    ]\n    client.submit_dag(\"DEEP_PIPELINE\", deep_tasks)\n</code></pre>"},{"location":"examples/agentic/#3-agentic-workflows-llms-mode-2","title":"3. Agentic Workflows &amp; LLMs (Mode 2)","text":"<p>Best for: AI Agents, Self-Healing loops, and recursive execution.</p> <p>In this mode, Titan acts as the physical execution substrate for Software Agents. Because Titan is completely decoupled, an LLM (like GPT-4 or Gemini) can evaluate the output of a previous task and dynamically formulate a brand new TitanJob to execute.</p> <p>The task graph itself is generated dynamically during execution.</p> <p>The \"Self-Healing\" Loop Imagine an agent that monitors a distributed job. It fetches the remote execution logs, and if it detects a critical failure, it programmatically creates a new \"Patch\" job to remediate the issue on the fly.</p> <pre><code>from titan_sdk import TitanClient, TitanJob\n\nclient = TitanClient()\njob_id = \"flaky_training_run\"\n\n# 1. Fetch remote execution logs via Titan's protocol\nlogs = client.fetch_logs(job_id)\n\n# 2. AI/Logic Evaluation\nif \"Segfault\" in logs or \"OutOfMemory\" in logs:\n    print(f\"[ERROR] CRITICAL ERROR in {job_id}. Agent is deploying a patch...\")\n\n    # Programmatically create a new job to fix the issue\n    fix_job = TitanJob(\n        job_id=f\"{job_id}_fix\", \n        filename=\"scripts/safe_mode_patch.py\",\n        requirement=\"GENERAL\"\n    )\n\n    # Dispatch the new task to the cluster\n    client.submit_job(fix_job)\nelse:\n    print(\"[SUCCESS] Run healthy. Agent sequence complete.\")\n</code></pre>"},{"location":"examples/agentic/#4-stateful-agents-using-titanstore-for-memory","title":"4. Stateful Agents (Using TitanStore for Memory)","text":"<p>Best for: Recursive agents, distributed web scrapers, and global state tracking.</p> <p>When an autonomous agent decides to respawn itself or dispatch sub-agents across different physical nodes, it loses its local Python variables. To maintain a \"train of thought\" across the cluster, agents can use Titan's built-in <code>TitanStore</code> as a shared global memory.</p>"},{"location":"examples/agentic/#the-recursive-agent-pattern","title":"The \"Recursive Agent\" Pattern","text":"<p>In this example, an autonomous agent tries to execute a fragile network task. If it fails, it increments a global counter in TitanStore and spawns a clone of itself to try again. If it fails 3 times, it realizes the system is down and escalates to a human instead of infinite-looping.</p> <p>File: <code>autonomous_agent.py</code> <pre><code>from titan_sdk import TitanClient, TitanJob\nimport random\n\nclient = TitanClient()\n\n# 1. Agent wakes up and checks its global memory\n# (Defaults to 0 if this is the first time running)\ncurrent_attempts = int(client.store_get(\"agent_retry_count\") or 0)\n\nprint(f\"[INFO] Agent Booting... (Attempt {current_attempts + 1} of 3)\")\n\nif current_attempts &gt;= 3:\n    print(\"[ESCALATION] Task failed 3 times. Halting recursion and alerting human.\")\n    client.store_put(\"agent_retry_count\", \"0\") # Reset for future runs\n    exit(1)\n\n# 2. Attempt the fragile task (e.g., calling an unstable API)\napi_success = random.choice([True, False])\n\nif api_success:\n    print(\"[SUCCESS] Task completed! Agent terminating.\")\n    client.store_put(\"agent_retry_count\", \"0\") # Reset memory\nelse:\n    print(\"[WARNING] Task failed. Agent logging failure and respawning...\")\n\n    # 3. Update global memory so the NEXT clone knows what happened\n    client.store_put(\"agent_retry_count\", str(current_attempts + 1))\n\n    # 4. Agent dynamically spawns a clone of itself to try again!\n    retry_job = TitanJob(\n        job_id=f\"agent_retry_{current_attempts + 1}\", \n        filename=\"autonomous_agent.py\"\n    )\n    client.submit_job(retry_job)\n</code></pre></p> <p>Why this is powerful: You only need to submit autonomous_agent.py to the cluster once. From that point on, the agent manages its own lifecycle, hops between available hardware nodes using Titan's scheduler, and uses the distributed store to remember its past failures until the job succeeds.</p>"},{"location":"examples/dagster/","title":"\ud83d\udc19 Hybrid Orchestration (Dagster + Titan)","text":"<p>Best for: Enterprise environments that want Dagster's UI and data lineage, but Titan's hardware-aware compute.</p> <p>In this mode, you separate the Control Plane from the Data Plane. Dagster acts as the logical DAG layer (managing the UI, lineage, and metadata), while Titan assumes responsibility for the physical execution\u2014turning a control-plane-only scheduler into a hardware-aware distributed runtime.</p>"},{"location":"examples/dagster/#why-use-this-pattern","title":"Why use this pattern?","text":"<p>By integrating Titan as a Dagster Resource, you gain:</p> <ol> <li>Hardware-Aware Routing: Dagster itself cannot easily route a specific Python function to a remote machine with a GPU. Titan handles this transparently.</li> <li>Infrastructure Elasticity: Titan auto-scales the underlying hardware nodes based on the load Dagster throws at it.</li> <li>Unified Logging: Titan's SDK streams the remote execution logs from isolated physical workers directly back into the local Dagster UI.</li> </ol>"},{"location":"examples/dagster/#the-integration-code","title":"The Integration Code","text":"<p>You can bridge the two systems by extending <code>dg.ConfigurableResource</code>. This creates a custom <code>TitanEngine</code> that submits the job and runs a synchronous polling loop to stream the status and logs back to Dagster.</p> <p>File: <code>pipeline.py</code> <pre><code>import time\nimport dagster as dg\nfrom titan_sdk import TitanClient, TitanJob\n\nclass TitanEngine(dg.ConfigurableResource):\n    \"\"\"\n    The official bridge to the Titan Distributed Engine.\n    Handles TCP dispatch and synchronous polling.\n    \"\"\"\n    def run_task(self, context: dg.AssetExecutionContext, script_path: str, requirement: str = \"GENERAL\", affinity: bool = False):\n        client = TitanClient()\n\n        # Extract the logical asset name (e.g., \"raw_data\")\n        step_name = context.asset_key.path[-1]\n\n        t_job = TitanJob(\n            job_id=step_name,\n            filename=script_path,\n            job_type=\"RUN_PAYLOAD\", \n            requirement=requirement,\n            affinity=affinity, \n            is_archive=False \n        )\n\n        context.log.info(f\"\ud83d\ude80 Routing '{step_name}' to Titan (Req: {requirement}, Affinity: {affinity})\")\n        client.submit_job(t_job)\n\n        # Synchronous Polling Loop via Titan's Status API\n        master_job_id = f\"DAG-{step_name}\"\n        while True:\n            status = client.get_job_status(master_job_id)\n            if status == \"COMPLETED\":\n                # Fetch logs on success for full visibility\n                worker_logs = client.fetch_logs(master_job_id)\n                context.log.info(f\"\u2705 Titan Worker Logs:\\n{worker_logs}\")\n                context.log.info(f\"\u2705 Titan finished physical execution of '{step_name}'!\")\n                return True\n\n            elif status == \"FAILED\":\n                # Fetch logs on failure to debug within Dagster\n                worker_logs = client.fetch_logs(master_job_id)\n                context.log.error(f\"\u274c Titan Worker failed. Remote Logs:\\n{worker_logs}\")\n                raise Exception(f\"\u274c Titan Worker failed on '{step_name}'.\")\n\n            time.sleep(2)\n\n# --- The Logical Assets ---\n@dg.asset\ndef raw_data(context: dg.AssetExecutionContext, titan: TitanEngine):\n    \"\"\"Step 1: General extraction task.\"\"\"\n    titan.run_task(context, script_path=\"extract.py\", requirement=\"GENERAL\", affinity=False)\n\n@dg.asset\ndef trained_model(context: dg.AssetExecutionContext, titan: TitanEngine, raw_data):\n    \"\"\"Step 2: Heavy GPU task. Forced to same node as Step 1.\"\"\"\n    titan.run_task(context, script_path=\"train.py\", requirement=\"GPU\", affinity=True)\n\n@dg.asset\ndef evaluation_metrics(context: dg.AssetExecutionContext, titan: TitanEngine, trained_model):\n    \"\"\"Step 3: Lightweight CPU task. No affinity needed.\"\"\"\n    titan.run_task(context, script_path=\"eval.py\", requirement=\"GENERAL\", affinity=False)\n\n# --- Workspace Configuration ---\ndefs = dg.Definitions(\n    assets=[raw_data, trained_model, evaluation_metrics],\n    # We bind the Titan engine to the workspace here\n    resources={\"titan\": TitanEngine()} \n)\n</code></pre></p>"},{"location":"examples/dagster/#dagster-execution-dashboard","title":"Dagster Execution Dashboard","text":"<p>What happens under the hood:</p> <ul> <li> <p>Dagster evaluates the logical asset dependency graph.</p> </li> <li> <p>When an asset unblocks, Dagster triggers the titan.run_task() function.</p> </li> <li> <p>Titan translates that asset into a TitanJob, finds an available node matching the requirement (like GPU), and dispatches the code.</p> </li> <li> <p>The Dagster process waits in a while True loop, querying Titan for the status.</p> </li> <li> <p>Once the remote node finishes, Titan pulls the stdout/stderr logs across the network and prints them natively into the Dagster UI!</p> </li> </ul>"},{"location":"examples/dagster/#sequence-diagram","title":"Sequence Diagram","text":"<p>Dagster holds the logical execution graph and delegates physical execution to Titan via a synchronous polling loop.</p> <p></p>"},{"location":"examples/yaml/","title":"\ud83d\udcc4 Static Pipelines (YAML)","text":"<p>Best for: Scheduled tasks, ETL pipelines, and known dependencies.</p> <p>For standard infrastructure tasks, you don't need to write Python orchestration code. You can define deterministic DAGs in a declarative YAML file. Titan will automatically parse this, zip your scripts, and distribute them to the cluster.</p>"},{"location":"examples/yaml/#1-the-basics-the-diamond-pattern","title":"1. The Basics: The Diamond Pattern","text":"<p>If you just want to run tasks and don't care which node they land on, keep it simple. If you omit the <code>requirement</code> field, Titan automatically defaults to routing tasks to <code>GENERAL</code> workers. </p> <p>Here is a minimal \"Diamond Pattern\" DAG where a root task fans out into two parallel tasks, which then converge into a single sink.</p> <p>Create a file named <code>diamond-flow.yaml</code>:</p> <pre><code>name: \"diamond-flow-style\"\nversion: \"1.0\"\nproject: true # Tells Titan to zip the surrounding folder\n\njobs:\n  - id: \"root\"\n    type: \"run\"\n    file: \"scripts/init.py\"\n\n  - id: \"left\"\n    type: \"run\"\n    file: \"src/processor.py\"\n    depends_on: [\"root\"]\n\n  - id: \"right\"\n    type: \"run\"\n    file: \"src/processor.py\"\n    depends_on: [\"root\"]\n\n  - id: \"sink\"\n    type: \"run\"\n    file: \"scripts/init.py\"\n    depends_on: [\"left\", \"right\"]\n</code></pre>"},{"location":"examples/yaml/#deploying-the-pipeline","title":"Deploying the Pipeline","text":"<p>Use the Titan CLI to submit this DAG to your cluster:</p> <pre><code>python titan_sdk/titan_cli.py deploy diamond-flow.yaml\n</code></pre>"},{"location":"examples/yaml/#how-titan-handles-this","title":"How Titan Handles This:","text":"<ol> <li> <p>Root is queued immediately.</p> </li> <li> <p>Once root succeeds, Titan detects that left and right are both unblocked and dispatches them simultaneously to available workers.</p> </li> <li> <p>Sink waits until both parallel tasks finish successfully before executing</p> </li> </ol>"},{"location":"examples/yaml/#2-advanced-hardware-aware-routing","title":"2. Advanced: Hardware-Aware Routing","text":"<p>When you have a heterogeneous cluster (e.g., some cheap CPU VMs and one expensive GPU machine), you can use the <code>requirement</code> tag to enforce strict node affinity.</p> <pre><code>jobs:\n  - id: \"Data_Prep\"\n    type: \"run\"\n    file: \"scripts/clean_data.py\"\n    # Defaults to GENERAL. Will run on any standard node.\n\n  - id: \"Train_Model\"\n    type: \"run\"\n    file: \"scripts/train.py\"\n    depends_on: [\"Data_Prep\"]\n    requirement: \"GPU\" # Titan guarantees this ONLY lands on a GPU-tagged node\n</code></pre>"},{"location":"examples/yaml/#deploying-the-pipeline_1","title":"Deploying the Pipeline","text":"<p>Use the Titan CLI to submit your YAML DAG to the active cluster:</p> <pre><code>python titan_sdk/titan_cli.py deploy diamond-flow.yaml\n</code></pre>"},{"location":"examples/yaml/#3-deploying-a-long-running-service","title":"3. Deploying a Long-Running Service","text":"<p>Titan isn't just for ephemeral scripts; it can act as a Micro-PaaS to host APIs. Use type: service to tell the worker to keep the process alive.</p> <pre><code>jobs:\n  - id: \"FastAPI_Backend\"\n    type: \"service\"\n    file: \"src/server.py\"\n    port: 8000 # Required for services\n    args: \"--host 0.0.0.0 --reload\"\n</code></pre>"},{"location":"examples/yaml/#deploying-the-pipeline_2","title":"Deploying the Pipeline","text":"<p>Use the Titan CLI to submit any YAML DAG to the active cluster: <pre><code>python titan_sdk/titan_cli.py deploy my_pipeline.yaml\n</code></pre></p>"},{"location":"examples/yaml/#4-advanced-combined-essentials-version","title":"4. Advanced: Combined Essentials version","text":"<p>If you need fine-grained control over execution timing, hardware locality, and background services, Titan supports advanced scheduling flags. </p> <p>This example demonstrates queue priorities, artificial delays, strict task affinity (forcing a task to run on the exact same physical node as its parent to leverage local file caches), and deploying a long-running background service.</p> <p>Create <code>comprehensive-flow.yaml</code>:</p> <pre><code>name: \"titan-comprehensive-test\"\nproject: true  # Activates Archive/Sandbox Mode\n\njobs:\n  # SCENARIO 1: High Priority Task\n  - id: \"step-1-init\"\n    type: \"run\"\n    file: \"scripts/init.py\"\n    priority: 10              # Highest priority in the queue\n    args: \"--mode reset\"\n\n  # SCENARIO 2: Delayed Execution\n  - id: \"step-2-fetch\"\n    type: \"run\"\n    file: \"src/processor.py\"\n    args: \"FETCH\"\n    delay: 2                  # Scheduler waits 2 seconds after unblocking\n    depends_on: [\"step-1-init\"]\n\n  # SCENARIO 3: Sticky Scheduling (Affinity)\n  - id: \"step-3-process\"\n    type: \"run\"\n    file: \"src/processor.py\"\n    args: \"PROCESS_DATA\"\n    affinity: true            # MUST run on the exact worker that ran 'step-2-fetch'\n    depends_on: [\"step-2-fetch\"]\n\n  # SCENARIO 4: Long-Running Service\n  - id: \"step-4-server\"\n    type: \"service\"\n    file: \"src/server.py\"\n    port: 9000                # Keeps the process alive and binds to this port\n    depends_on: [\"step-3-process\"]\n</code></pre>"},{"location":"examples/yaml/#deploying-the-pipeline_3","title":"Deploying the Pipeline","text":"<p>Use the Titan CLI to submit your YAML DAG to the active cluster:</p> <pre><code>python titan_sdk/titan_cli.py deploy comprehensive-flow.yaml\n</code></pre>"},{"location":"examples/yaml/#full-yaml-schema-reference","title":"\ud83d\udcda Full YAML Schema Reference","text":""},{"location":"examples/yaml/#root-level-parameters","title":"Root Level Parameters","text":"Field Type Default Description <code>name</code> String <code>titan_agent</code> The name of the project. Used when naming the generated zip artifact. <code>project</code> Boolean <code>true</code> If <code>true</code>, Titan zips the entire surrounding folder and sends it to the worker. If <code>false</code>, it attempts to run the file using an absolute path on the worker node. <code>jobs</code> List <code>[]</code> A list of job definition blocks."},{"location":"examples/yaml/#job-level-parameters","title":"Job Level Parameters","text":"Field Type Default Description <code>id</code> String Required A unique identifier for the task within this DAG. <code>file</code> String Required The relative path to the script to execute. <code>type</code> String <code>run</code> <code>run</code> for ephemeral tasks. <code>service</code> for long-running servers. <code>depends_on</code> List[String] <code>[]</code> A list of parent ids that must complete successfully before this task runs. <code>requirement</code> String <code>GENERAL</code> The hardware tag required to run this task (e.g., <code>GPU</code>, <code>HIGH_MEM</code>). <code>priority</code> Integer <code>1</code> Queue priority. Higher numbers are scheduled first. <code>delay</code> Integer <code>0</code> Delay in seconds before the task is allowed to execute after unblocking. <code>affinity</code> Boolean <code>false</code> If <code>true</code>, Titan attempts to route this task to the exact same physical node as its parent task to leverage local file caching. <code>port</code> Integer None Required if <code>type: service</code>. The network port the service will bind to. <code>args</code> String <code>\"\"</code> Command-line arguments appended to the execution command."},{"location":"javadocs/docs/legal/jquery/","title":"Jquery","text":""},{"location":"javadocs/docs/legal/jquery/#jquery-v371","title":"jQuery v3.7.1","text":""},{"location":"javadocs/docs/legal/jquery/#jquery-license","title":"jQuery License","text":"<pre><code>jQuery v 3.7.1\nCopyright OpenJS Foundation and other contributors, https://openjsf.org/\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n</code></pre>"},{"location":"javadocs/docs/legal/jqueryUI/","title":"jqueryUI","text":""},{"location":"javadocs/docs/legal/jqueryUI/#jquery-ui-v1132","title":"jQuery UI v1.13.2","text":""},{"location":"javadocs/docs/legal/jqueryUI/#jquery-ui-license","title":"jQuery UI License","text":"<pre><code>Copyright jQuery Foundation and other contributors, https://jquery.org/\n\nThis software consists of voluntary contributions made by many\nindividuals. For exact contribution history, see the revision history\navailable at https://github.com/jquery/jquery-ui\n\nThe following license applies to all parts of this software except as\ndocumented below:\n\n====\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n====\n\nCopyright and related rights for sample code are waived via CC0. Sample\ncode is defined as all source code contained within the demos directory.\n\nCC0: http://creativecommons.org/publicdomain/zero/1.0/\n\n====\n\nAll files located in the node_modules and external directories are\nexternally maintained libraries used by this software which have their\nown licenses; we recommend you read them, as their terms may differ from\nthe terms above.\n</code></pre>"},{"location":"reference/cli/","title":"\ud83d\udcbb Operator Manual (CLI)","text":"<p>The Titan CLI is a Java-based interactive shell that connects directly to the Master node. It allows cluster operators to view real-time system health, manually deploy services, and kill rogue tasks.</p>"},{"location":"reference/cli/#connecting-to-the-cluster","title":"Connecting to the Cluster","text":"<p>To launch the CLI, run the <code>TitanCli</code> class from your built artifact. It will automatically attempt to connect to the Master on <code>localhost:9090</code>.</p> <pre><code>java -cp perm_files/Worker.jar client.TitanCli\n</code></pre> <p>Supported Commands:</p> Command Description <code>stats</code> View cluster health, active nodes, and job queues. <code>run &lt;file&gt;</code> Immediately execute a script from <code>perm_files</code>. <code>deploy &lt;file&gt; [port]</code> Deploy a single file or service. Supports capability requirements. Ex: deploy train.py 0 GPU <code>deploy Worker.jar &lt;port&gt; [capability]</code> Manually spawn a new Worker node on a specific port with its capability (GPU or GENERAL) <code>stop &lt;service_id&gt;</code> Gracefully stop a running service or job. <code>shutdown &lt;host&gt; &lt;port&gt;</code> Remotely decommission a specific worker node. <code>dag &lt;dag_string&gt;</code> Submit a raw DAG string (Advanced users). <code>upload &lt;local_path&gt;</code> Upload a file to server storage (perm_files)"},{"location":"reference/cli/#the-cli-interface","title":"The CLI Interface","text":"<p>When you run the stats command, the CLI provides a real-time snapshot of the ActiveJobQueue, the WaitingQueue (Blocked DAGs), and the exact load on every connected worker node. It also explicitly lists all Live Services currently hosted on the cluster.</p> <pre><code>==========================================\n    [INFO] TITAN DISTRIBUTED ORCHESTRATOR    \n==========================================\nConnected to: localhost:9090\nCommands: stats, json, submit &lt;skill&gt; &lt;data&gt;, dag &lt;raw_dag&gt;, exit\n\ntitan&gt; stats\n--- TITAN SYSTEM MONITOR ---\nActive Workers:    3\nExecution Queue:   0 jobs\nBlocked (DAG):     1 jobs\n-------------------------------\nWorker Status:\n \u2022 [8080] Load: 2/4 (50%)    | Skills: [GENERAL]\n    \u2514\u2500\u2500 \u2699\ufe0f Service ID: DAG-JOB_SPAWN\n    \u2514\u2500\u2500 \u2699\ufe0f Service ID: DAG-step-4-server\n \u2022 [8081] Load: 0/4 (0%)     | Skills: [GENERAL]\n</code></pre>"},{"location":"reference/cli/#how-to-read-the-monitor","title":"How to Read the Monitor","text":"<ul> <li> <p>Execution Queue: The number of tasks that are fully unblocked and waiting for an available worker slot. If this number is high and stays high, your cluster is under-provisioned and needs more workers.</p> </li> <li> <p>Blocked (DAG): Tasks that are safely waiting in the WaitingQueue because their parent dependencies have not finished yet.</p> </li> <li> <p>Load (e.g., 2/4 (50%)): Indicates that this specific worker is currently executing 2 concurrent tasks out of its maximum thread capacity of 4.</p> </li> <li> <p>Skills: The capability tags assigned to that node (e.g., [GENERAL], [GPU]), dictating what kind of tasks the Master is allowed to route to it.</p> </li> <li> <p>Live Services: The CLI explicitly lists long-running processes hosted on the node under the worker stats.</p> <pre><code>WRK- Prefix: Indicates a dynamically spawned Worker instance.\n\nTSK- Prefix: Indicates a deployed long-running service (like an API, web server, or persistent agent).\n</code></pre> </li> <li> <p>Ephemeral Scripts are Hidden: The list only shows live services. Fast, ephemeral scripts are not printed by name in the tree to prevent console spam; their execution is simply reflected in the active Load percentage and the total jobs information.</p> </li> </ul>"},{"location":"reference/sdk/","title":"\ud83d\udcda Python SDK Reference","text":"<p>The Titan Python SDK allows you to programmatically define jobs, interact with the TitanStore data bus, and manage distributed artifacts.</p>"},{"location":"reference/sdk/#1-core-classes","title":"1. Core Classes","text":""},{"location":"reference/sdk/#titanclient","title":"<code>TitanClient</code>","text":"<p>The main entry point for connecting to the cluster.</p> <pre><code>from titan_sdk import TitanClient\n\n# Initialize connection (defaults to localhost:9090)\nclient = TitanClient(host=\"localhost\", port=9090)\n</code></pre> Method Description <code>client.submit_job(job)</code> Dispatches a single <code>TitanJob</code> to the cluster. <code>client.submit_dag(name, jobs)</code> Submits a list of linked <code>TitanJob</code> objects as a single DAG. <code>client.get_job_status(job_id)</code> Securely queries the Master for a job's internal system status. <code>client.fetch_logs(job_id)</code> Retrieves the stdout/stderr logs for a specific job ID. <code>client.upload_project_folder(path)</code> Zips and uploads a local folder to the Master's artifact registry. <code>client.upload_file(filepath)</code> Uploads a single file to the Master's artifact registry. <code>client.store_put(key, value)</code> Saves a string value to the distributed TitanStore (Data Bus). <code>client.store_get(key)</code> Retrieves a string value from the distributed TitanStore. <code>client.store_sadd(key, member)</code> Adds a member to a distributed Set. Returns 1 if new, 0 if exists. <code>client.store_smembers(key)</code> Returns a Python list of all members in the specified Set."},{"location":"reference/sdk/#titanjob","title":"<code>TitanJob</code>","text":"<p>Represents a unit of work to be executed on the cluster.</p> <pre><code>from titan_sdk import TitanJob\n\njob = TitanJob(\n    job_id=\"train_v1\",\n    filename=\"scripts/train.py\",\n    requirement=\"GPU\",     # Optional: \"GPU\" or \"GENERAL\"\n    priority=10,           # Optional: Higher numbers schedule first\n    parents=[\"data_prep\"], # Optional: List of parent Job IDs\n    is_archive=False       # Set True if deploying a ZIP/Service\n)\n</code></pre> <p>These are the constructor parameters:</p> Parameter Type Default Description <code>job_id</code> <code>str</code> Required Unique identifier for this execution step. <code>filename</code> <code>str</code> Required Absolute or relative path to the script or artifact. <code>job_type</code> <code>str</code> <code>\"RUN_PAYLOAD\"</code> Defines execution mode (e.g., use <code>\"SERVICE\"</code> for long-running processes). <code>args</code> <code>str</code> <code>None</code> Command-line arguments passed to the executed script. <code>parents</code> <code>list</code> <code>None</code> List of parent <code>job_id</code>s that must complete successfully before this task runs. <code>port</code> <code>int</code> <code>0</code> Port number to bind to (Required if deploying a long-running Service). <code>is_archive</code> <code>bool</code> <code>False</code> Set to <code>True</code> if deploying a zipped project folder. <code>priority</code> <code>int</code> <code>1</code> Queue priority. Higher numbers are scheduled first. <code>delay</code> <code>int</code> <code>0</code> Artificial delay (in seconds/ms depending on scheduler) before execution. <code>affinity</code> <code>bool</code> <code>False</code> If <code>True</code>, Titan attempts to route this task to the exact same physical node as its parent task. <code>requirement</code> <code>str</code> <code>\"GENERAL\"</code> Hardware capability routing tag (e.g., <code>\"GPU\"</code>, <code>\"HIGH_MEM\"</code>)."},{"location":"reference/sdk/#2-defining-dags-programmatically","title":"2. Defining DAGs Programmatically","text":"<p>You can build dependency graphs using the SDK's API instead of YAML.</p> <pre><code>from titan_sdk import TitanClient, TitanJob\n\nclient = TitanClient()\n\n# Step 1: Define the Root Job (No parents)\ntask_a = TitanJob(\n    job_id=\"extract_data\",\n    filename=\"etl/extract.py\",\n    priority=5\n)\n\n# Step 2: Define a Dependent Job\ntask_b = TitanJob(\n    job_id=\"train_model\",\n    filename=\"ml/train.py\",\n    requirement=\"GPU\",\n    parents=[\"extract_data\"] # &lt;--- Defines the dependency\n)\n\n# Step 3: Submit them as a unified DAG\nclient.submit_dag(\"nightly_pipeline\", [task_a, task_b])\nprint(\"DAG Submitted!\")\n</code></pre>"},{"location":"reference/sdk/#3-using-the-distributed-data-bus-titanstore","title":"3. Using the Distributed Data Bus (TitanStore)","text":"<p>Tasks running on completely different physical nodes can share state, pass intermediate variables, or track metrics using Titan's built-in persistence layer.</p> <p>File 1: <code>task_a.py</code> (Producer)</p> <pre><code>from titan_sdk import TitanClient\n\nclient = TitanClient()\n# Save a result globally before the task exits\nclient.store_put(\"task_123_accuracy\", \"98.5\")\nclient.store_sadd(\"processed_files\", \"batch_A.csv\")\n</code></pre> <p>File 2: <code>task_b.py</code> (Consumer)</p> <pre><code>from titan_sdk import TitanClient\n\nclient = TitanClient()\n# Retrieve the data passed from Task A\naccuracy = client.store_get(\"task_123_accuracy\")\ncompleted_files = client.store_smembers(\"processed_files\")\n\nprint(f\"Downstream task received accuracy: {accuracy}\")\n</code></pre>"}]}